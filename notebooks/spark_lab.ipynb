{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b570b505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Spark Version: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "# cell 1\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to the system path so we can import from 'src'\n",
    "# This assumes the notebook is inside a 'notebooks' folder\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import our custom modules\n",
    "from src.utils import get_spark_session\n",
    "from src.config import API_KEY, BASE_URL, MOVIE_IDS\n",
    "from src.ingestion import fetch_movie_data\n",
    "from src.cleaning import clean_movie_data\n",
    "from src.analysis import get_ranked_movies, analyze_franchises\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Spark\n",
    "spark = get_spark_session(\"TMDB_Analysis_Lab\")\n",
    "print(f\"Spark Version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88260b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 19 movies...\n",
      "Fetching 1/19: ID 0...\n",
      "  Warning: Movie ID 0 not found.\n",
      "Fetching 2/19: ID 299534...\n",
      "Fetching 3/19: ID 19995...\n",
      "Fetching 4/19: ID 140607...\n",
      "Fetching 5/19: ID 299536...\n",
      "Fetching 6/19: ID 597...\n",
      "Fetching 7/19: ID 135397...\n",
      "Fetching 8/19: ID 420818...\n",
      "Fetching 9/19: ID 24428...\n",
      "Fetching 10/19: ID 168259...\n",
      "Fetching 11/19: ID 99861...\n",
      "Fetching 12/19: ID 284054...\n",
      "Fetching 13/19: ID 12445...\n",
      "Fetching 14/19: ID 181808...\n",
      "Fetching 15/19: ID 330457...\n",
      "Fetching 16/19: ID 351286...\n",
      "Fetching 17/19: ID 109445...\n",
      "Fetching 18/19: ID 321612...\n",
      "Fetching 19/19: ID 260513...\n",
      "Raw Schema:\n",
      "root\n",
      " |-- adult: boolean (nullable = true)\n",
      " |-- backdrop_path: string (nullable = true)\n",
      " |-- belongs_to_collection: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = true)\n",
      " |-- budget: long (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: long (valueContainsNull = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- imdb_id: string (nullable = true)\n",
      " |-- origin_country: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- overview: string (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- poster_path: string (nullable = true)\n",
      " |-- production_companies: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: long (valueContainsNull = true)\n",
      " |-- production_countries: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- release_date: string (nullable = true)\n",
      " |-- revenue: long (nullable = true)\n",
      " |-- runtime: long (nullable = true)\n",
      " |-- spoken_languages: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- video: boolean (nullable = true)\n",
      " |-- vote_average: double (nullable = true)\n",
      " |-- vote_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cell 2\n",
    "# 1. Fetch raw data using Python (Driver Node)\n",
    "print(f\"Fetching data for {len(MOVIE_IDS)} movies...\")\n",
    "raw_data_list = fetch_movie_data(MOVIE_IDS, API_KEY, BASE_URL)\n",
    "\n",
    "# 2. Convert to Spark DataFrame\n",
    "# Spark automatically infers the schema from the list of dicts\n",
    "df_raw = spark.createDataFrame(raw_data_list)\n",
    "\n",
    "print(\"Raw Schema:\")\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e5b1dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"genres[name]\" due to data type mismatch: Parameter 2 requires the \"INTEGRAL\" type, however \"name\" has the type \"STRING\".;\n'Project [backdrop_path#53, belongs_to_collection#125L, budget#55L, array_join(genres#56[name], |, None) AS genres#148, id#58L, origin_country#60, original_language#61, overview#63, popularity#64, poster_path#65, production_companies#66, production_countries#67, release_date#68, revenue#69L, runtime#70L, spoken_languages#71, status#72, tagline#73, title#74, vote_average#76, vote_count#77L]\n+- Project [backdrop_path#53, belongs_to_collection#54[name] AS belongs_to_collection#125L, budget#55L, genres#56, id#58L, origin_country#60, original_language#61, overview#63, popularity#64, poster_path#65, production_companies#66, production_countries#67, release_date#68, revenue#69L, runtime#70L, spoken_languages#71, status#72, tagline#73, title#74, vote_average#76, vote_count#77L]\n   +- Project [backdrop_path#53, belongs_to_collection#54, budget#55L, genres#56, id#58L, origin_country#60, original_language#61, overview#63, popularity#64, poster_path#65, production_companies#66, production_countries#67, release_date#68, revenue#69L, runtime#70L, spoken_languages#71, status#72, tagline#73, title#74, vote_average#76, vote_count#77L]\n      +- LogicalRDD [adult#52, backdrop_path#53, belongs_to_collection#54, budget#55L, genres#56, homepage#57, id#58L, imdb_id#59, origin_country#60, original_language#61, original_title#62, overview#63, popularity#64, poster_path#65, production_companies#66, production_countries#67, release_date#68, revenue#69L, runtime#70L, spoken_languages#71, status#72, tagline#73, title#74, video#75, ... 2 more fields], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# cell 3\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Apply our Spark cleaning pipeline\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_clean = \u001b[43mclean_movie_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_raw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Cache the result since we will use this dataframe for multiple analyses\u001b[39;00m\n\u001b[32m      6\u001b[39m df_clean.cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CourageDei\\Desktop\\Moodle\\DE\\DE05\\Module Lab 1- TMDB Movie Data Analysis using Pandas and APIs\\src\\cleaning.py:29\u001b[39m, in \u001b[36mclean_movie_data\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     24\u001b[39m array_cols = [\u001b[33m'\u001b[39m\u001b[33mgenres\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mproduction_countries\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mproduction_companies\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mspoken_languages\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col_name \u001b[38;5;129;01min\u001b[39;00m array_cols:\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# col_name.name extracts an array of names [\"Action\", \"Thriller\"]\u001b[39;00m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# array_join converts it to \"Action|Thriller\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcol_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 3. Handle Numeric Conversions & Missing Values\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Convert Budget/Revenue to Millions and Handle 0s\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mbudget\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrevenue\u001b[39m\u001b[33m'\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CourageDei\\Desktop\\Moodle\\DE\\DE05\\Module Lab 1- TMDB Movie Data Analysis using Pandas and APIs\\.venv\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:5170\u001b[39m, in \u001b[36mDataFrame.withColumn\u001b[39m\u001b[34m(self, colName, col)\u001b[39m\n\u001b[32m   5165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[32m   5166\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[32m   5167\u001b[39m         error_class=\u001b[33m\"\u001b[39m\u001b[33mNOT_COLUMN\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5168\u001b[39m         message_parameters={\u001b[33m\"\u001b[39m\u001b[33marg_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcol\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33marg_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col).\u001b[34m__name__\u001b[39m},\n\u001b[32m   5169\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m5170\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m.sparkSession)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CourageDei\\Desktop\\Moodle\\DE\\DE05\\Module Lab 1- TMDB Movie Data Analysis using Pandas and APIs\\.venv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CourageDei\\Desktop\\Moodle\\DE\\DE05\\Module Lab 1- TMDB Movie Data Analysis using Pandas and APIs\\.venv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    181\u001b[39m converted = convert_exception(e.java_exception)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[32m    184\u001b[39m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mAnalysisException\u001b[39m: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"genres[name]\" due to data type mismatch: Parameter 2 requires the \"INTEGRAL\" type, however \"name\" has the type \"STRING\".;\n'Project [backdrop_path#53, belongs_to_collection#125L, budget#55L, array_join(genres#56[name], |, None) AS genres#148, id#58L, origin_country#60, original_language#61, overview#63, popularity#64, poster_path#65, production_companies#66, production_countries#67, release_date#68, revenue#69L, runtime#70L, spoken_languages#71, status#72, tagline#73, title#74, vote_average#76, vote_count#77L]\n+- Project [backdrop_path#53, belongs_to_collection#54[name] AS belongs_to_collection#125L, budget#55L, genres#56, id#58L, origin_country#60, original_language#61, overview#63, popularity#64, poster_path#65, production_companies#66, production_countries#67, release_date#68, revenue#69L, runtime#70L, spoken_languages#71, status#72, tagline#73, title#74, vote_average#76, vote_count#77L]\n   +- Project [backdrop_path#53, belongs_to_collection#54, budget#55L, genres#56, id#58L, origin_country#60, original_language#61, overview#63, popularity#64, poster_path#65, production_companies#66, production_countries#67, release_date#68, revenue#69L, runtime#70L, spoken_languages#71, status#72, tagline#73, title#74, vote_average#76, vote_count#77L]\n      +- LogicalRDD [adult#52, backdrop_path#53, belongs_to_collection#54, budget#55L, genres#56, homepage#57, id#58L, imdb_id#59, origin_country#60, original_language#61, original_title#62, overview#63, popularity#64, poster_path#65, production_companies#66, production_countries#67, release_date#68, revenue#69L, runtime#70L, spoken_languages#71, status#72, tagline#73, title#74, video#75, ... 2 more fields], false\n"
     ]
    }
   ],
   "source": [
    "# cell 3\n",
    "# Apply our Spark cleaning pipeline\n",
    "df_clean = clean_movie_data(df_raw)\n",
    "\n",
    "# Cache the result since we will use this dataframe for multiple analyses\n",
    "df_clean.cache()\n",
    "\n",
    "print(f\"Cleaned Row Count: {df_clean.count()}\")\n",
    "df_clean.select(\"title\", \"release_date\", \"revenue_musd\", \"roi\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4\n",
    "print(\"--- Top 5 Highest Revenue ---\")\n",
    "top_rev = get_ranked_movies(df_clean, \"revenue_musd\", ascending=False)\n",
    "top_rev.select(\"title\", \"revenue_musd\", \"budget_musd\").show()\n",
    "\n",
    "print(\"--- Top 5 Highest ROI ---\")\n",
    "top_roi = get_ranked_movies(df_clean, \"roi\", ascending=False)\n",
    "top_roi.select(\"title\", \"roi\", \"revenue_musd\").show()\n",
    "\n",
    "print(\"--- Worst 5 Flops (Lowest ROI) ---\")\n",
    "# Filter for significant budget first to avoid divide-by-zero anomalies on micro-films\n",
    "flop_roi = get_ranked_movies(df_clean.filter(\"budget_musd > 10\"), \"roi\", ascending=True)\n",
    "flop_roi.select(\"title\", \"roi\", \"budget_musd\", \"revenue_musd\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff6825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5\n",
    "# Compare Franchises vs Standalone\n",
    "franchise_stats = analyze_franchises(df_clean)\n",
    "\n",
    "# Collect to Pandas for display\n",
    "pdf_franchise = franchise_stats.toPandas()\n",
    "display(pdf_franchise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 6\n",
    "# Collect necessary data to Pandas (Drivers only)\n",
    "# Warning: Only do this on aggregated or filtered data in production!\n",
    "pdf_plot = df_clean.select(\"title\", \"budget_musd\", \"revenue_musd\", \"roi\", \"popularity\").toPandas()\n",
    "\n",
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# 1. Budget vs Revenue Scatter Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=pdf_plot, x=\"budget_musd\", y=\"revenue_musd\", size=\"roi\", hue=\"roi\", sizes=(20, 200), palette=\"viridis\")\n",
    "\n",
    "plt.title(\"Movie Budget vs. Revenue (Size = ROI)\")\n",
    "plt.xlabel(\"Budget (Million USD)\")\n",
    "plt.ylabel(\"Revenue (Million USD)\")\n",
    "plt.axline((0, 0), slope=1, color=\".5\", linestyle=\"--\", label=\"Break-even\") # Break-even line\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\n",
    "# Label top movies\n",
    "for i in range(pdf_plot.shape[0]):\n",
    "    if pdf_plot.revenue_musd[i] > 500 or pdf_plot.roi[i] > 5: # Only label hits\n",
    "        plt.text(pdf_plot.budget_musd[i]+2, pdf_plot.revenue_musd[i], \n",
    "                 pdf_plot.title[i], fontsize=9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c36e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 7\n",
    "# We need to 'explode' the genre string back into rows for this plot\n",
    "# \"Action|Sci-Fi\" -> \n",
    "# Row 1: Action\n",
    "# Row 2: Sci-Fi\n",
    "from pyspark.sql.functions import explode, split\n",
    "\n",
    "df_exploded = df_clean.withColumn(\"genre\", explode(split(\"genres\", \"\\|\")))\n",
    "genre_roi = df_exploded.groupBy(\"genre\").mean(\"roi\").toPandas().sort_values(\"avg(roi)\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=genre_roi, x=\"avg(roi)\", y=\"genre\", palette=\"magma\")\n",
    "plt.title(\"Average ROI by Genre\")\n",
    "plt.xlabel(\"Average ROI\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
